import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_sound/flutter_sound.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import '../services/ai_service.dart';
import 'local_data_screen.dart';
import '../services/storage_service.dart';

class NaturalChatScreen extends StatefulWidget {
  final bool intakeMode;
  final String? location;
  final String? weather;

  const NaturalChatScreen({super.key})
      : intakeMode = false,
        location = null,
        weather = null;

  const NaturalChatScreen.intake({
    super.key,
    required this.location,
    required this.weather,
  }) : intakeMode = true;

  @override
  State<NaturalChatScreen> createState() => _NaturalChatScreenState();
}

class _NaturalChatScreenState extends State<NaturalChatScreen> with SingleTickerProviderStateMixin {
  // ğŸ› ï¸ ë„êµ¬ë“¤
  final stt.SpeechToText _speech = stt.SpeechToText();
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final FlutterTts _flutterTts = FlutterTts();
  
  // ğŸ“Š ìƒíƒœ ë³€ìˆ˜
  bool _isListening = false; 
  bool _isThinking = false;   
  bool _isSpeechAvailable = false; 
  String _userText = "";       
  String _aiText = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?";
  String? _recordedFilePath;
  bool _isRecording = false;
  DateTime? _recordingStartedAt;
  int _intakeStep = 0;
  final Map<String, String> _intakeAnswers = {};
  static const List<String> _intakeQuestions = [
    "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë–¤ê°€ìš”? ì˜ˆ) ì¢€ ì§€ì³¤ì–´ / ê´œì°®ì€ í¸ì´ì•¼",
    "ì§€ê¸ˆ ì–´ë””ì— ìˆë‚˜ìš”? ì˜ˆ) ë°© / ê±°ì‹¤ / ì¹¨ëŒ€ ìœ„",
    "ì§€ê¸ˆ ë¬´ì—‡ì„ í•˜ê³  ìˆë‚˜ìš”? ì˜ˆ) ëˆ„ì›Œìˆì–´ / ì•‰ì•„ì„œ ì‰¬ëŠ” ì¤‘",
  ];
  static const List<String> _intakeEmpathy = [
    "ë§í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ì§€ê¸ˆ ëŠë‚Œì„ ì†Œì¤‘í•˜ê²Œ ë“¤ì—ˆì–´ìš”.",
    "ê´œì°®ì•„ìš”, í¸í•˜ê²Œ ë§í•´ì¤˜ì„œ ì¢‹ì•„ìš”.",
    "ì§€ê¸ˆ ìƒíƒœë¥¼ ì•Œë ¤ì¤˜ì„œ ì •ë§ ë„ì›€ì´ ëì–´ìš”.",
  ];

  // âœ¨ ì• ë‹ˆë©”ì´ì…˜ ê´€ë ¨
  double _buttonSize = 90.0;
  Timer? _animTimer;

  // ğŸ“ ëŒ€í™” ê¸°ë¡
  static List<Map<String, String>> _cachedHistory = [];
  List<Map<String, String>> _chatHistory = [];
  final ScrollController _scrollController = ScrollController();

  final AIService _aiService = AIService();

  @override
  void initState() {
    super.initState();
    _chatHistory = List<Map<String, String>>.from(_cachedHistory);
    _initSystem();
  }

  Future<void> _initSystem() async {
    print("--- ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘ ---");
    
    // 1. ê¶Œí•œ ìš”ì²­
    await [Permission.microphone, Permission.speech].request();

    // 2. ë…¹ìŒê¸° ì´ˆê¸°í™”
    await _recorder.openRecorder();

    // 3. STT(ìŒì„± ì¸ì‹) ì´ˆê¸°í™”
    _isSpeechAvailable = await _speech.initialize(
      onError: (val) => print('STT ì—ëŸ¬: $val'),
      onStatus: (val) {
        print('STT ìƒíƒœ: $val');
        // ë§í•˜ë‹¤ê°€ ë©ˆì¶”ë©´ ìë™ìœ¼ë¡œ ë²„íŠ¼ ìƒíƒœ ë³€ê²½ ë“±ë„ ê°€ëŠ¥
      },
    );
    print("STT ì´ˆê¸°í™” ì—¬ë¶€: $_isSpeechAvailable");

    // 4. TTS ì„¤ì •
    await _flutterTts.setLanguage("ko-KR");
    await _flutterTts.setSpeechRate(0.5);

    // 5. ì²« ì¸ì‚¬
    if (_chatHistory.isEmpty) {
      if (widget.intakeMode) {
        _aiText = "ì§€ê¸ˆ ìƒíƒœë¥¼ ì²œì²œíˆ ê°™ì´ ì‚´í´ë³¼ê²Œìš”. í¸í•˜ê²Œ ë§í•´ì¤˜ìš”.";
      }
      _addChatMessage("ai", _aiText);
      _flutterTts.speak(_aiText);
      if (widget.intakeMode) {
        _askNextIntakeQuestion();
      }
    }
  }

  // ğŸ¤ ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
  void _toggleListening() {
    if (_isThinking) return;

    if (_isListening) {
      _stopListening();
    } else {
      _startListening();
    }
  }

  // ğŸ‘‚ ë“£ê¸° ì‹œì‘ (STT + ë¡œì»¬ ë…¹ìŒ)
  Future<void> _startListening() async {
    print(">>> 1. ë“£ê¸° ì‹œì‘ (STT + ë…¹ìŒ) <<<");
    await _flutterTts.stop(); // AI ë§ ëŠê¸°

    setState(() {
      _isListening = true;
      _userText = ""; // í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    });
    _startAnimation();

    // ğŸ™ï¸ ë…¹ìŒ íŒŒì¼ ìƒì„± (ì•± ë‚´ë¶€ ì €ì¥ì†Œ)
    try {
      final dir = await getApplicationDocumentsDirectory();
      final fileName = "voice_${DateTime.now().millisecondsSinceEpoch}.m4a";
      _recordedFilePath = "${dir.path}/$fileName";

      await _recorder.startRecorder(
        toFile: _recordedFilePath,
        codec: Codec.aacMP4,
      );
      _isRecording = true;
      _recordingStartedAt = DateTime.now();
      print("ë…¹ìŒ ì‹œì‘: $_recordedFilePath");
    } catch (e) {
      print("ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e");
      _recordedFilePath = null;
      _isRecording = false;
      _recordingStartedAt = null;
    }

    // âš ï¸ ë…¹ìŒê³¼ STT ë™ì‹œ ì‚¬ìš© ì‹œ ì¶©ëŒ ê°€ëŠ¥ â†’ ë…¹ìŒì´ ì¼œì§€ë©´ STTëŠ” ê±´ë„ˆëœ€
    if (_isSpeechAvailable && !_isRecording) {
      _speech.listen(
        onResult: (val) {
          setState(() {
            _userText = val.recognizedWords; // ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ê¸€ì í‘œì‹œ
          });
          print("ì¸ì‹ëœ ê¸€ì: ${val.recognizedWords}");
        },
        localeId: 'ko_KR',
        listenFor: const Duration(seconds: 30),
        pauseFor: const Duration(seconds: 3), // 3ì´ˆ ì‰¬ë©´ ìë™ ì™„ë£Œ
        listenMode: stt.ListenMode.dictation,
        cancelOnError: false,
        partialResults: true, // ë§í•˜ëŠ” ë„ì¤‘ì—ë„ ê¸€ì ë„ìš°ê¸°
      );
    } else if (!_isRecording) {
      print("âš ï¸ STT ì´ˆê¸°í™” ì‹¤íŒ¨ (ì¬ì‹œë„ í•„ìš”)");
      _isSpeechAvailable = await _speech.initialize();
    }
  }

  // ğŸ›‘ ë“£ê¸° ì¢…ë£Œ -> AI ì „ì†¡
  Future<void> _stopListening() async {
    print(">>> 2. ë“£ê¸° ì¢…ë£Œ <<<");
    
    await _speech.stop();
    if (_isRecording) {
      try {
        await _recorder.stopRecorder();
        _isRecording = false;
        if (_recordedFilePath != null) {
          print("ë…¹ìŒ ì¢…ë£Œ: $_recordedFilePath");
        }
      } catch (e) {
        _isRecording = false;
        print("ë…¹ìŒ ì¢…ë£Œ ì‹¤íŒ¨: $e");
      }
    }
    _stopAnimation();

    setState(() {
      _isListening = false;
      _isThinking = true; 
    });

    // ìµœì¢… í…ìŠ¤íŠ¸ í™•ì¸
    String finalText = _userText.trim();
    File? audioFile;
    if (_recordedFilePath != null) {
      final candidate = File(_recordedFilePath!);
      if (await candidate.exists()) {
        final size = await candidate.length();
        if (size > 0) {
          audioFile = candidate;
        } else {
          print("âš ï¸ ë…¹ìŒ íŒŒì¼ í¬ê¸° 0: $_recordedFilePath");
        }
      } else {
        print("âš ï¸ ë…¹ìŒ íŒŒì¼ ì—†ìŒ: $_recordedFilePath");
      }
    }

    if (finalText.isEmpty && audioFile == null) {
      if (!mounted) return;
      setState(() => _isThinking = false);
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text("ìŒì„±ì´ ì œëŒ€ë¡œ ë…¹ìŒë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ¤")),
      );
      return; 
    }
    
    // âœ… ë‚´ ë§í’ì„  ì¶”ê°€
    if (finalText.isNotEmpty) {
      _addChatMessage("user", finalText);
    } else {
      _addChatMessage("user", "(ìŒì„± ë©”ì‹œì§€)");
    }

    // AIì—ê²Œ ì „ì†¡ (í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ ì „ì‚¬)
    final started = _recordingStartedAt;
    final durationMs = started != null ? DateTime.now().difference(started).inMilliseconds : null;
    _recordingStartedAt = null;
    await _processAiResponse(finalText, audioFile: audioFile, durationMs: durationMs);
  }

  // ğŸ¤– AI ì‘ë‹µ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ê¸°ë°˜)
  Future<void> _processAiResponse(String userText, {File? audioFile, int? durationMs}) async {
    try {
      print(">>> 3. AIì—ê²Œ í…ìŠ¤íŠ¸ ì „ì†¡: $userText <<<");

      String finalText = userText;
      if (finalText.isEmpty && audioFile != null) {
        try {
          finalText = await _aiService.transcribeAudio(audioFile);
          if (finalText.isNotEmpty) {
            // ë°©ê¸ˆ ì¶”ê°€í•œ (ìŒì„± ë©”ì‹œì§€) ë²„ë¸”ì„ ì‹¤ì œ í…ìŠ¤íŠ¸ë¡œ êµì²´
            if (_chatHistory.isNotEmpty &&
                _chatHistory.last['role'] == 'user' &&
                _chatHistory.last['text'] == '(ìŒì„± ë©”ì‹œì§€)') {
              setState(() {
                _chatHistory[_chatHistory.length - 1] = {
                  "role": "user",
                  "text": finalText
                };
                _cachedHistory = List<Map<String, String>>.from(_chatHistory);
              });
              _scrollToBottom();
            }
          }
        } catch (e) {
          print("ì „ì‚¬ ì‹¤íŒ¨: $e");
        }
      }
      
      if (widget.intakeMode) {
        await _handleIntakeFlow(finalText);
        return;
      }

      final aiResponseText = await _aiService.processVoiceChat(
        userText: finalText,
        audioFile: audioFile,
        chatHistory: _chatHistory,
      );

      // ìŒì„± ì‹ í˜¸ ì €ì¥ (ê¸¸ì´/ë¹ˆë„ ì§€í‘œ)
      if (durationMs != null) {
        await StorageService.addVoiceSignal(
          durationMs: durationMs,
          transcriptLength: finalText.length,
          hasSpeech: finalText.isNotEmpty,
        );
      }

      if (!mounted) return;

      setState(() {
        _aiText = aiResponseText;
        _isThinking = false;
      });
      
      _addChatMessage("ai", aiResponseText);
      await _flutterTts.speak(aiResponseText);

    } catch (e) {
      print("AI Error: $e");
      if (!mounted) return;
      setState(() => _isThinking = false);
      _addChatMessage("ai", "ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?");
    }
  }

  void _addChatMessage(String role, String text) {
    if (!mounted) return;
    setState(() {
      _chatHistory.add({"role": role, "text": text});
      _cachedHistory = List<Map<String, String>>.from(_chatHistory);
    });
    _scrollToBottom();
  }

  void _scrollToBottom() {
    if (!_scrollController.hasClients) return;
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (!_scrollController.hasClients) return;
      _scrollController.animateTo(
        _scrollController.position.maxScrollExtent,
        duration: const Duration(milliseconds: 250),
        curve: Curves.easeOut,
      );
    });
  }

  void _startAnimation() {
    _animTimer?.cancel();
    _animTimer = Timer.periodic(const Duration(milliseconds: 600), (_) {
      if (mounted) setState(() => _buttonSize = (_buttonSize == 90.0) ? 110.0 : 90.0);
    });
  }
  
  void _stopAnimation() {
    _animTimer?.cancel();
    if (mounted) setState(() => _buttonSize = 90.0);
  }

  @override
  void dispose() {
    _saveChatSummary();
    _animTimer?.cancel();
    _scrollController.dispose();
    _recorder.closeRecorder();
    _speech.cancel();
    _flutterTts.stop();
    super.dispose();
  }

  void _saveChatSummary() {
    if (_chatHistory.isEmpty) return;
    // fire-and-forget
    _aiService.summarizeChat(_chatHistory).then((summary) {
      if (summary == null) return;
      final String text = (summary['summary'] ?? '').toString();
      final List<String> keywords = (summary['keywords'] is List)
          ? (summary['keywords'] as List).map((e) => e.toString()).toList()
          : <String>[];
      StorageService.saveChatSummary(text, keywords);
    });
  }

  Future<void> _handleIntakeFlow(String userText) async {
    if (userText.trim().isEmpty) {
      setState(() => _isThinking = false);
      return;
    }

    // ê³µê° í•œë§ˆë””
    final empathy = _intakeEmpathy[_intakeStep.clamp(0, _intakeEmpathy.length - 1)];
    _addChatMessage("ai", empathy);
    _flutterTts.speak(empathy);

    if (_intakeStep == 0) {
      _intakeAnswers['condition'] = userText.trim();
    } else if (_intakeStep == 1) {
      _intakeAnswers['place'] = userText.trim();
    } else if (_intakeStep == 2) {
      _intakeAnswers['activity'] = userText.trim();
    }

    _intakeStep++;

    if (_intakeStep < _intakeQuestions.length) {
      _askNextIntakeQuestion();
      setState(() => _isThinking = false);
      return;
    }

    if (!mounted) return;
    final selected = await showDialog<String>(
      context: context,
      barrierDismissible: false,
      builder: (ctx) => AlertDialog(
        title: const Text("ì˜¤ëŠ˜ì€ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ í• ê¹Œìš”?"),
        content: const Text("ì‰¬ì–´ê°€ê¸° / ê°€ë³ê²Œ / ë³´í†µ ì¤‘ì—ì„œ ê³¨ë¼ì£¼ì„¸ìš”."),
        actions: [
          TextButton(
            onPressed: () => Navigator.pop(ctx, "REST"),
            child: const Text("ì‰¬ì–´ê°ˆê²Œìš”"),
          ),
          TextButton(
            onPressed: () => Navigator.pop(ctx, "LIGHT"),
            child: const Text("ê°€ë³ê²Œ í• ë˜ìš”"),
          ),
          TextButton(
            onPressed: () => Navigator.pop(ctx, "NORMAL"),
            child: const Text("ë³´í†µìœ¼ë¡œ í•´ì¤˜"),
          ),
        ],
      ),
    );

    Navigator.pop(context, {
      ..._intakeAnswers,
      "user_choice": selected ?? "NORMAL",
    });
  }

  void _askNextIntakeQuestion() {
    if (_intakeStep >= _intakeQuestions.length) return;
    final q = _intakeQuestions[_intakeStep];
    _addChatMessage("ai", q);
    _flutterTts.speak(q);
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: const Color(0xFFF0F4F8),
      appBar: AppBar(
        title: const Text("ë§ˆìŒ ìƒë‹´ì†Œ", style: TextStyle(color: Colors.black87, fontWeight: FontWeight.bold)), 
        centerTitle: true, 
        elevation: 0, 
        backgroundColor: Colors.transparent,
        iconTheme: const IconThemeData(color: Colors.black87),
        actions: [
          IconButton(
            icon: const Icon(Icons.folder_open),
            tooltip: "ë¡œì»¬ ë°ì´í„° í™•ì¸",
            onPressed: () {
              Navigator.push(
                context,
                MaterialPageRoute(builder: (_) => const LocalDataScreen()),
              );
            },
          )
        ],
      ),
      body: Column(
        children: [
          Expanded(
            child: ListView.builder(
              controller: _scrollController,
              padding: const EdgeInsets.all(20),
              itemCount: _chatHistory.length,
              itemBuilder: (context, index) {
                final chat = _chatHistory[index];
                final isUser = chat['role'] == 'user';
                return Align(
                  alignment: isUser ? Alignment.centerRight : Alignment.centerLeft,
                  child: Container(
                    margin: const EdgeInsets.symmetric(vertical: 8), 
                    padding: const EdgeInsets.symmetric(horizontal: 18, vertical: 12),
                    constraints: BoxConstraints(maxWidth: MediaQuery.of(context).size.width * 0.75),
                    decoration: BoxDecoration(
                      color: isUser ? const Color(0xFF6BB8B0) : Colors.white,
                      borderRadius: BorderRadius.only(
                        topLeft: const Radius.circular(20),
                        topRight: const Radius.circular(20),
                        bottomLeft: isUser ? const Radius.circular(20) : const Radius.circular(5),
                        bottomRight: isUser ? const Radius.circular(5) : const Radius.circular(20),
                      ),
                      boxShadow: [BoxShadow(color: Colors.black12, blurRadius: 5, offset: const Offset(0, 2))],
                    ),
                    child: Text(
                      chat['text']!,
                      style: TextStyle(color: isUser ? Colors.white : Colors.black87, fontSize: 16, height: 1.4),
                    ),
                  ),
                );
              },
            ),
          ),
          
          Container(
            padding: const EdgeInsets.only(bottom: 40, top: 25, left: 20, right: 20),
            decoration: const BoxDecoration(
              color: Colors.white,
              borderRadius: BorderRadius.vertical(top: Radius.circular(30)),
              boxShadow: [BoxShadow(color: Colors.black12, blurRadius: 15, offset: Offset(0, -5))]
            ),
            child: Column(
              children: [
                if (_isListening)
                  Padding(
                    padding: const EdgeInsets.only(bottom: 20),
                    child: Text(
                      _userText.isEmpty ? "ë“£ê³  ìˆì–´ìš”... ë§ì”€í•´ ë³´ì„¸ìš” ğŸ‘‚" : _userText,
                      textAlign: TextAlign.center,
                      style: const TextStyle(fontSize: 18, color: Color(0xFF6BB8B0), fontWeight: FontWeight.w600),
                    ),
                  )
                else if (_isThinking) 
                  const Padding(
                    padding: EdgeInsets.only(bottom: 20),
                    child: Text("ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ¤”", style: TextStyle(fontSize: 16, color: Colors.grey)),
                  ),
                
                GestureDetector(
                  onTap: _toggleListening,
                  child: AnimatedContainer(
                    duration: const Duration(milliseconds: 300),
                    width: _buttonSize, height: _buttonSize,
                    decoration: BoxDecoration(
                      color: _isListening ? const Color(0xFFFF6B6B) : const Color(0xFF6BB8B0),
                      shape: BoxShape.circle,
                      boxShadow: [BoxShadow(color: (_isListening ? Colors.red : Colors.teal).withOpacity(0.4), blurRadius: 15, spreadRadius: 5)]
                    ),
                    child: Icon(
                      _isThinking ? Icons.more_horiz : (_isListening ? Icons.stop : Icons.mic),
                      color: Colors.white, size: 40,
                    ),
                  ),
                ),
              ],
            ),
          ),
        ],
      ),
    );
  }
}
