import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_sound/flutter_sound.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import '../services/ai_service.dart';
import '../services/audio_analysis_service.dart';
import 'local_data_screen.dart';
import '../services/storage_service.dart';

class NaturalChatScreen extends StatefulWidget {
  final bool intakeMode;
  final String? location;
  final String? weather;
  final bool enableMic;

  const NaturalChatScreen({super.key})
      : intakeMode = false,
        location = null,
        weather = null,
        enableMic = true;

  const NaturalChatScreen.intake({
    super.key,
    required this.location,
    required this.weather,
  })  : intakeMode = true,
        enableMic = true;

  const NaturalChatScreen.readOnly({super.key})
      : intakeMode = false,
        location = null,
        weather = null,
        enableMic = false;

  @override
  State<NaturalChatScreen> createState() => _NaturalChatScreenState();
}

class _NaturalChatScreenState extends State<NaturalChatScreen> with SingleTickerProviderStateMixin {
  // ğŸ› ï¸ ë„êµ¬ë“¤
  final stt.SpeechToText _speech = stt.SpeechToText();
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final FlutterTts _flutterTts = FlutterTts();
  
  // ğŸ“Š ìƒíƒœ ë³€ìˆ˜
  bool _isListening = false; 
  bool _isThinking = false;   
  bool _isSpeechAvailable = false; 
  String _userText = "";       
  String _aiText = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?";
  String? _recordedFilePath;
  bool _isRecording = false;
  DateTime? _recordingStartedAt;
  int _intakeStep = 0;
  final Map<String, String> _intakeAnswers = {};
  static const List<String> _intakeQuestions = [
    "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë–¤ê°€ìš”? ì˜ˆ) ì¢€ ì§€ì³¤ì–´ / ê´œì°®ì€ í¸ì´ì•¼",
    "ì§€ê¸ˆ ì–´ë””ì— ìˆë‚˜ìš”? ì˜ˆ) ë°© / ê±°ì‹¤ / ì¹¨ëŒ€ ìœ„",
    "ì§€ê¸ˆ ë¬´ì—‡ì„ í•˜ê³  ìˆë‚˜ìš”? ì˜ˆ) ëˆ„ì›Œìˆì–´ / ì•‰ì•„ì„œ ì‰¬ëŠ” ì¤‘",
  ];
  static const List<String> _intakeEmpathy = [
    "ë§í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ì§€ê¸ˆ ëŠë‚Œì„ ì†Œì¤‘í•˜ê²Œ ë“¤ì—ˆì–´ìš”.",
    "ê´œì°®ì•„ìš”, í¸í•˜ê²Œ ë§í•´ì¤˜ì„œ ì¢‹ì•„ìš”.",
    "ì§€ê¸ˆ ìƒíƒœë¥¼ ì•Œë ¤ì¤˜ì„œ ì •ë§ ë„ì›€ì´ ëì–´ìš”.",
  ];

  // âœ¨ ì• ë‹ˆë©”ì´ì…˜ ê´€ë ¨
  double _buttonSize = 90.0;
  Timer? _animTimer;

  // ğŸ“ ëŒ€í™” ê¸°ë¡
  static List<Map<String, String>> _cachedHistory = [];
  static List<Map<String, String>> _cachedIntakeHistory = [];
  List<Map<String, String>> _chatHistory = [];
  List<Map<String, dynamic>> _sampleUsers = [];
  int _selectedUserIndex = 0;
  final ScrollController _scrollController = ScrollController();

  final AIService _aiService = AIService();
  final AudioAnalysisService _audioAnalysisService = AudioAnalysisService();

  @override
  void initState() {
    super.initState();
    _chatHistory = widget.intakeMode
        ? List<Map<String, String>>.from(_cachedIntakeHistory)
        : List<Map<String, String>>.from(_cachedHistory);
    if (!widget.enableMic) {
      _sampleUsers = _buildSampleUsers();
      _applySelectedUserChat();
    }
    _initSystem();
    WidgetsBinding.instance.addPostFrameCallback((_) => _scrollToBottom());
  }

  Future<void> _initSystem() async {
    print("--- ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘ ---");

    if (!widget.enableMic) {
      if (_chatHistory.isEmpty) {
        _aiText = "ëŒ€í™” ë‚´ìš© ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤.";
        _addChatMessage("ai", _aiText);
      }
      return;
    }
    
    // 1. ê¶Œí•œ ìš”ì²­
    await [Permission.microphone, Permission.speech].request();

    // 2. ë…¹ìŒê¸° ì´ˆê¸°í™”
    await _recorder.openRecorder();

    // 3. STT(ìŒì„± ì¸ì‹) ì´ˆê¸°í™”
    _isSpeechAvailable = await _speech.initialize(
      onError: (val) => print('STT ì—ëŸ¬: $val'),
      onStatus: (val) {
        print('STT ìƒíƒœ: $val');
        // ë§í•˜ë‹¤ê°€ ë©ˆì¶”ë©´ ìë™ìœ¼ë¡œ ë²„íŠ¼ ìƒíƒœ ë³€ê²½ ë“±ë„ ê°€ëŠ¥
      },
    );
    print("STT ì´ˆê¸°í™” ì—¬ë¶€: $_isSpeechAvailable");

    // 4. TTS ì„¤ì •
    await _flutterTts.setLanguage("ko-KR");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.awaitSpeakCompletion(true);

    // 5. ì²« ì¸ì‚¬
    if (_chatHistory.isEmpty) {
      if (widget.intakeMode) {
        _aiText = "ì§€ê¸ˆ ìƒíƒœë¥¼ ì²œì²œíˆ ê°™ì´ ì‚´í´ë³¼ê²Œìš”. í¸í•˜ê²Œ ë§í•´ì¤˜ìš”.";
      }
      _addChatMessage("ai", _aiText);
      await _speakAndWait(_aiText);
      if (widget.intakeMode) {
        await _askNextIntakeQuestion();
      }
    } else if (!widget.intakeMode) {
      // ì‚¬ìš©ìê°€ ìì˜ë¡œ ë“¤ì–´ì˜¤ë©´ ë‹¤ì‹œ ì¸ì‚¬
      final greet = "ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ì‹œ ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. ì˜¤ëŠ˜ì€ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ í•´ë³¼ê¹Œìš”?";
      _addChatMessage("ai", greet);
      await _speakAndWait(greet);
    }
  }

  // ğŸ¤ ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
  void _toggleListening() {
    if (_isThinking) return;

    if (_isListening) {
      _stopListening();
    } else {
      _startListening();
    }
  }

  // ğŸ‘‚ ë“£ê¸° ì‹œì‘ (STT + ë¡œì»¬ ë…¹ìŒ)
  Future<void> _startListening() async {
    print(">>> 1. ë“£ê¸° ì‹œì‘ (STT + ë…¹ìŒ) <<<");
    await _flutterTts.stop(); // AI ë§ ëŠê¸°

    setState(() {
      _isListening = true;
      _userText = ""; // í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    });
    _startAnimation();

    // ğŸ™ï¸ ë…¹ìŒ íŒŒì¼ ìƒì„± (ì•± ë‚´ë¶€ ì €ì¥ì†Œ)
    try {
      final dir = await getApplicationDocumentsDirectory();
      final fileName = "voice_${DateTime.now().millisecondsSinceEpoch}.m4a";
      _recordedFilePath = "${dir.path}/$fileName";

      await _recorder.startRecorder(
        toFile: _recordedFilePath,
        codec: Codec.aacMP4,
      );
      _isRecording = true;
      _recordingStartedAt = DateTime.now();
      print("ë…¹ìŒ ì‹œì‘: $_recordedFilePath");
    } catch (e) {
      print("ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e");
      _recordedFilePath = null;
      _isRecording = false;
      _recordingStartedAt = null;
    }

    // âš ï¸ ë…¹ìŒê³¼ STT ë™ì‹œ ì‚¬ìš© ì‹œ ì¶©ëŒ ê°€ëŠ¥ â†’ ë…¹ìŒì´ ì¼œì§€ë©´ STTëŠ” ê±´ë„ˆëœ€
    if (_isSpeechAvailable && !_isRecording) {
      _speech.listen(
        onResult: (val) {
          setState(() {
            _userText = val.recognizedWords; // ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ê¸€ì í‘œì‹œ
          });
          print("ì¸ì‹ëœ ê¸€ì: ${val.recognizedWords}");
        },
        localeId: 'ko_KR',
        listenFor: const Duration(seconds: 30),
        pauseFor: const Duration(seconds: 3), // 3ì´ˆ ì‰¬ë©´ ìë™ ì™„ë£Œ
        listenMode: stt.ListenMode.dictation,
        cancelOnError: false,
        partialResults: true, // ë§í•˜ëŠ” ë„ì¤‘ì—ë„ ê¸€ì ë„ìš°ê¸°
      );
    } else if (!_isRecording) {
      print("âš ï¸ STT ì´ˆê¸°í™” ì‹¤íŒ¨ (ì¬ì‹œë„ í•„ìš”)");
      _isSpeechAvailable = await _speech.initialize();
    }
  }

  // ğŸ›‘ ë“£ê¸° ì¢…ë£Œ -> AI ì „ì†¡
  Future<void> _stopListening() async {
    print(">>> 2. ë“£ê¸° ì¢…ë£Œ <<<");
    
    await _speech.stop();
    if (_isRecording) {
      try {
        await _recorder.stopRecorder();
        _isRecording = false;
        if (_recordedFilePath != null) {
          print("ë…¹ìŒ ì¢…ë£Œ: $_recordedFilePath");
        }
      } catch (e) {
        _isRecording = false;
        print("ë…¹ìŒ ì¢…ë£Œ ì‹¤íŒ¨: $e");
      }
    }
    _stopAnimation();

    setState(() {
      _isListening = false;
      _isThinking = true; 
    });

    // ìµœì¢… í…ìŠ¤íŠ¸ í™•ì¸
    String finalText = _userText.trim();
    File? audioFile;
    if (_recordedFilePath != null) {
      final candidate = File(_recordedFilePath!);
      if (await candidate.exists()) {
        final size = await candidate.length();
        if (size > 0) {
          audioFile = candidate;
        } else {
          print("âš ï¸ ë…¹ìŒ íŒŒì¼ í¬ê¸° 0: $_recordedFilePath");
        }
      } else {
        print("âš ï¸ ë…¹ìŒ íŒŒì¼ ì—†ìŒ: $_recordedFilePath");
      }
    }

    if (finalText.isEmpty && audioFile == null) {
      if (!mounted) return;
      setState(() => _isThinking = false);
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text("ìŒì„±ì´ ì œëŒ€ë¡œ ë…¹ìŒë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ¤")),
      );
      return; 
    }
    
    // âœ… ë‚´ ë§í’ì„  ì¶”ê°€
    if (finalText.isNotEmpty) {
      _addChatMessage("user", finalText);
    } else {
      _addChatMessage("user", "(ìŒì„± ë©”ì‹œì§€)");
    }

    // AIì—ê²Œ ì „ì†¡ (í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ ì „ì‚¬)
    final started = _recordingStartedAt;
    final durationMs = started != null ? DateTime.now().difference(started).inMilliseconds : null;
    _recordingStartedAt = null;
    await _processAiResponse(finalText, audioFile: audioFile, durationMs: durationMs);
  }

  // ğŸ¤– AI ì‘ë‹µ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ê¸°ë°˜)
  Future<void> _processAiResponse(String userText, {File? audioFile, int? durationMs}) async {
    try {
      print(">>> 3. AIì—ê²Œ í…ìŠ¤íŠ¸ ì „ì†¡: $userText <<<");

      String finalText = userText;
      List<dynamic>? wordTimestamps;
      if (audioFile != null) {
        try {
          final transcribed = await _aiService.transcribeAudioWithTimestamps(audioFile);
          final transcribedText = (transcribed['text'] ?? '').toString();
          if (transcribed['words'] is List) {
            wordTimestamps = transcribed['words'] as List<dynamic>;
          }
          if (finalText.isEmpty) {
            finalText = transcribedText;
          }
          if (finalText.isNotEmpty) {
            // ë°©ê¸ˆ ì¶”ê°€í•œ (ìŒì„± ë©”ì‹œì§€) ë²„ë¸”ì„ ì‹¤ì œ í…ìŠ¤íŠ¸ë¡œ êµì²´
            if (_chatHistory.isNotEmpty &&
                _chatHistory.last['role'] == 'user' &&
                _chatHistory.last['text'] == '(ìŒì„± ë©”ì‹œì§€)') {
              setState(() {
                _chatHistory[_chatHistory.length - 1] = {
                  "role": "user",
                  "text": finalText
                };
                _cachedHistory = List<Map<String, String>>.from(_chatHistory);
              });
              _scrollToBottom();
            }
          }
        } catch (e) {
          print("ì „ì‚¬ ì‹¤íŒ¨: $e");
        }
      }
      
      // ìŒì„± ì‹ í˜¸ ì €ì¥ (ê¸¸ì´/ë¹ˆë„ ì§€í‘œ) - intake/ì¼ë°˜ ëª¨ë‘ ë°˜ì˜
      if (durationMs != null) {
        final metrics = _buildVoiceMetricsFromWords(wordTimestamps, durationMs);
        await StorageService.addVoiceSignal(
          durationMs: durationMs,
          transcriptLength: finalText.length,
          hasSpeech: finalText.isNotEmpty,
          wpm: metrics?['wpm'] as double?,
          pauseRatio: metrics?['pause_ratio'] as double?,
          avgPauseMs: metrics?['avg_pause_ms'] as int?,
          utteranceCount: metrics?['utterance_count'] as int?,
          avgUtteranceWords: metrics?['avg_utterance_words'] as double?,
        );
      }

      // ì„œë²„ ìŒì„± ë¶„ì„ (ì‹¤ì‹œê°„) - ë¹„ë™ê¸° ì €ì¥
      if (audioFile != null && await audioFile.exists()) {
        final userId = await StorageService.getOrCreateDeviceId();
        _audioAnalysisService
            .analyzeAudio(audioFile: audioFile, userId: userId)
            .then((result) {
          if (result != null) {
            StorageService.addAudioAnalysis(result);
          }
        });
      }

      if (widget.intakeMode) {
        await _handleIntakeFlow(finalText);
        return;
      }

      final aiResponseText = await _aiService.processVoiceChat(
        userText: finalText,
        audioFile: audioFile,
        chatHistory: _chatHistory,
      );

      if (!mounted) return;

      setState(() {
        _aiText = aiResponseText;
        _isThinking = false;
      });
      
      _addChatMessage("ai", aiResponseText);
      await _flutterTts.speak(aiResponseText);

    } catch (e) {
      print("AI Error: $e");
      if (!mounted) return;
      setState(() => _isThinking = false);
      _addChatMessage("ai", "ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?");
    }
  }

  void _addChatMessage(String role, String text) {
    if (!mounted) return;
    setState(() {
      _chatHistory.add({"role": role, "text": text});
      if (widget.intakeMode) {
        _cachedIntakeHistory = List<Map<String, String>>.from(_chatHistory);
      } else {
        _cachedHistory = List<Map<String, String>>.from(_chatHistory);
      }
    });
    _scrollToBottom();
  }

  void _scrollToBottom() {
    if (!_scrollController.hasClients) return;
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (!_scrollController.hasClients) return;
      _scrollController.animateTo(
        _scrollController.position.maxScrollExtent,
        duration: const Duration(milliseconds: 250),
        curve: Curves.easeOut,
      );
    });
  }

  void _startAnimation() {
    _animTimer?.cancel();
    _animTimer = Timer.periodic(const Duration(milliseconds: 600), (_) {
      if (mounted) setState(() => _buttonSize = (_buttonSize == 90.0) ? 110.0 : 90.0);
    });
  }
  
  void _stopAnimation() {
    _animTimer?.cancel();
    if (mounted) setState(() => _buttonSize = 90.0);
  }

  @override
  void dispose() {
    if (!widget.intakeMode) {
      _saveChatSummary();
    }
    _animTimer?.cancel();
    _scrollController.dispose();
    if (widget.enableMic) {
      _recorder.closeRecorder();
      _speech.cancel();
      _flutterTts.stop();
    }
    super.dispose();
  }

  Future<void> _speakAndWait(String text) async {
    if (text.trim().isEmpty) return;
    await _flutterTts.stop();
    await _flutterTts.speak(text);
  }

  void _saveChatSummary() {
    if (_chatHistory.isEmpty) return;
    // fire-and-forget
    _aiService.summarizeChat(_chatHistory).then((summary) {
      if (summary == null) return;
      final String text = (summary['summary'] ?? '').toString();
      final List<String> keywords = (summary['keywords'] is List)
          ? (summary['keywords'] as List).map((e) => e.toString()).toList()
          : <String>[];
      StorageService.saveChatSummary(text, keywords);
    });
  }

  Future<void> _handleIntakeFlow(String userText) async {
    if (userText.trim().isEmpty) {
      setState(() => _isThinking = false);
      return;
    }

    // ê³µê° í•œë§ˆë””
    final empathy = _intakeEmpathy[_intakeStep.clamp(0, _intakeEmpathy.length - 1)];
    _addChatMessage("ai", empathy);
    await _speakAndWait(empathy);

    if (_intakeStep == 0) {
      _intakeAnswers['condition'] = userText.trim();
    } else if (_intakeStep == 1) {
      _intakeAnswers['place'] = userText.trim();
    } else if (_intakeStep == 2) {
      _intakeAnswers['activity'] = userText.trim();
    }

    _intakeStep++;

    if (_intakeStep < _intakeQuestions.length) {
      await _askNextIntakeQuestion();
      setState(() => _isThinking = false);
      return;
    }

    // âœ… intake ëŒ€í™”ë„ AI ë¦¬í¬íŠ¸ì— ë°˜ì˜ (ìš”ì•½/í‚¤ì›Œë“œ ì €ì¥)
    if (_chatHistory.isNotEmpty) {
      _aiService.summarizeChat(_chatHistory).then((summary) {
        if (summary == null) return;
        final String text = (summary['summary'] ?? '').toString();
        final List<String> keywords = (summary['keywords'] is List)
            ? (summary['keywords'] as List).map((e) => e.toString()).toList()
            : <String>[];
        StorageService.saveChatSummary(text, keywords);
      });
    }

    if (!mounted) return;
    final selected = await showDialog<String>(
      context: context,
      barrierDismissible: false,
      builder: (ctx) => AlertDialog(
        title: const Text("ì˜¤ëŠ˜ì€ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ í• ê¹Œìš”?"),
        content: const Text("ì‰¬ì–´ê°€ê¸° / ê°€ë³ê²Œ / ë³´í†µ ì¤‘ì—ì„œ ê³¨ë¼ì£¼ì„¸ìš”."),
        actions: [
          TextButton(
            onPressed: () => Navigator.pop(ctx, "REST"),
            child: const Text("ì‰¬ì–´ê°ˆê²Œìš”"),
          ),
          TextButton(
            onPressed: () => Navigator.pop(ctx, "LIGHT"),
            child: const Text("ê°€ë³ê²Œ í• ë˜ìš”"),
          ),
          TextButton(
            onPressed: () => Navigator.pop(ctx, "NORMAL"),
            child: const Text("ë³´í†µìœ¼ë¡œ í•´ì¤˜"),
          ),
        ],
      ),
    );

    Navigator.pop(context, {
      ..._intakeAnswers,
      "user_choice": selected ?? "NORMAL",
    });
  }

  Future<void> _askNextIntakeQuestion() async {
    if (_intakeStep >= _intakeQuestions.length) return;
    final q = _intakeQuestions[_intakeStep];
    final parts = _splitQuestionText(q);
    _addChatMessage("ai", q);
    await _speakAndWait(parts.$1);
  }

  Map<String, dynamic>? _buildVoiceMetricsFromWords(List<dynamic>? words, int durationMs) {
    if (words == null || words.isEmpty || durationMs <= 0) return null;
    final durationSec = durationMs / 1000.0;
    final wordCount = words.length;

    double totalPause = 0;
    double totalSpeech = 0;
    double? prevEnd;
    int utteranceCount = 1;
    int currentUtteranceWords = 0;
    int totalUtteranceWords = 0;

    for (final w in words) {
      final start = (w is Map && w['start'] != null) ? (w['start'] as num).toDouble() : null;
      final end = (w is Map && w['end'] != null) ? (w['end'] as num).toDouble() : null;
      if (start == null || end == null) continue;
      totalSpeech += (end - start).clamp(0.0, double.infinity);
      currentUtteranceWords++;

      if (prevEnd != null) {
        final gap = (start - prevEnd).clamp(0.0, double.infinity);
        if (gap > 0.8) {
          // 0.8ì´ˆ ì´ìƒ ë©ˆì¶¤ì´ë©´ ë°œí™” êµ¬ë¶„
          utteranceCount++;
          totalUtteranceWords += currentUtteranceWords;
          currentUtteranceWords = 0;
        }
        totalPause += gap;
      }
      prevEnd = end;
    }
    totalUtteranceWords += currentUtteranceWords;

    final wpm = (wordCount / (durationSec / 60.0));
    final pauseRatio = (totalPause / durationSec).clamp(0.0, 1.0);
    final avgPauseMs = wordCount > 1 ? ((totalPause / (wordCount - 1)) * 1000).round() : 0;
    final avgUtteranceWords = utteranceCount > 0 ? (totalUtteranceWords / utteranceCount) : wordCount.toDouble();

    return {
      'wpm': double.parse(wpm.toStringAsFixed(1)),
      'pause_ratio': double.parse(pauseRatio.toStringAsFixed(2)),
      'avg_pause_ms': avgPauseMs,
      'utterance_count': utteranceCount,
      'avg_utterance_words': double.parse(avgUtteranceWords.toStringAsFixed(1)),
    };
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: const Color(0xFFF0F4F8),
      appBar: AppBar(
        title: const Text("ë§ˆìŒ ìƒë‹´ì†Œ", style: TextStyle(color: Colors.black87, fontWeight: FontWeight.bold)), 
        centerTitle: true, 
        elevation: 0, 
        backgroundColor: Colors.transparent,
        iconTheme: const IconThemeData(color: Colors.black87),
      ),
      body: Column(
        children: [
          if (!widget.enableMic) _buildUserSelector(),
          Expanded(
            child: ListView.builder(
              controller: _scrollController,
              padding: const EdgeInsets.all(20),
              itemCount: _chatHistory.length,
              itemBuilder: (context, index) {
                final chat = _chatHistory[index];
                final isUser = chat['role'] == 'user';
                final messageText = chat['text'] ?? '';
                final isAi = chat['role'] == 'ai';
                final parts = isAi ? _splitQuestionText(messageText) : null;
                return Align(
                  alignment: isUser ? Alignment.centerRight : Alignment.centerLeft,
                  child: Container(
                    margin: const EdgeInsets.symmetric(vertical: 8), 
                    padding: const EdgeInsets.symmetric(horizontal: 18, vertical: 12),
                    constraints: BoxConstraints(maxWidth: MediaQuery.of(context).size.width * 0.75),
                    decoration: BoxDecoration(
                      color: isUser ? const Color(0xFF6BB8B0) : Colors.white,
                      borderRadius: BorderRadius.only(
                        topLeft: const Radius.circular(20),
                        topRight: const Radius.circular(20),
                        bottomLeft: isUser ? const Radius.circular(20) : const Radius.circular(5),
                        bottomRight: isUser ? const Radius.circular(5) : const Radius.circular(20),
                      ),
                      boxShadow: [BoxShadow(color: Colors.black12, blurRadius: 5, offset: const Offset(0, 2))],
                    ),
                    child: isAi && (parts?.$2.isNotEmpty ?? false)
                        ? Column(
                            crossAxisAlignment: CrossAxisAlignment.start,
                            children: [
                              Text(
                                parts!.$1,
                                style: TextStyle(color: isUser ? Colors.white : Colors.black87, fontSize: 16, height: 1.4),
                              ),
                              const SizedBox(height: 6),
                              Container(
                                padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 4),
                                decoration: BoxDecoration(
                                  color: Colors.black.withOpacity(0.04),
                                  borderRadius: BorderRadius.circular(8),
                                ),
                                child: Text(
                                  parts.$2,
                                  style: const TextStyle(
                                    color: Colors.black54,
                                    fontSize: 12,
                                    height: 1.3,
                                    fontStyle: FontStyle.italic,
                                  ),
                                ),
                              ),
                            ],
                          )
                        : Text(
                            messageText,
                            style: TextStyle(color: isUser ? Colors.white : Colors.black87, fontSize: 16, height: 1.4),
                          ),
                  ),
                );
              },
            ),
          ),
          
          Container(
            padding: const EdgeInsets.only(bottom: 40, top: 25, left: 20, right: 20),
            decoration: const BoxDecoration(
              color: Colors.white,
              borderRadius: BorderRadius.vertical(top: Radius.circular(30)),
              boxShadow: [BoxShadow(color: Colors.black12, blurRadius: 15, offset: Offset(0, -5))]
            ),
            child: Column(
              children: [
                if (!widget.enableMic)
                  const Padding(
                    padding: EdgeInsets.only(bottom: 10),
                    child: Text(
                      "ì´ í™”ë©´ì€ ëŒ€í™” ê¸°ë¡ í™•ì¸ìš©ì…ë‹ˆë‹¤.",
                      style: TextStyle(fontSize: 14, color: Colors.black54),
                    ),
                  ),
                if (_isListening)
                  Padding(
                    padding: const EdgeInsets.only(bottom: 20),
                    child: Text(
                      _userText.isEmpty ? "ë“£ê³  ìˆì–´ìš”... ë§ì”€í•´ ë³´ì„¸ìš” ğŸ‘‚" : _userText,
                      textAlign: TextAlign.center,
                      style: const TextStyle(fontSize: 18, color: Color(0xFF6BB8B0), fontWeight: FontWeight.w600),
                    ),
                  )
                else if (_isThinking) 
                  const Padding(
                    padding: EdgeInsets.only(bottom: 20),
                    child: Text("ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ¤”", style: TextStyle(fontSize: 16, color: Colors.grey)),
                  ),
                
                if (widget.enableMic)
                  GestureDetector(
                    onTap: _toggleListening,
                    child: AnimatedContainer(
                      duration: const Duration(milliseconds: 300),
                      width: _buttonSize, height: _buttonSize,
                      decoration: BoxDecoration(
                        color: _isListening ? const Color(0xFFFF6B6B) : const Color(0xFF6BB8B0),
                        shape: BoxShape.circle,
                        boxShadow: [BoxShadow(color: (_isListening ? Colors.red : Colors.teal).withOpacity(0.4), blurRadius: 15, spreadRadius: 5)]
                      ),
                      child: Icon(
                        _isThinking ? Icons.more_horiz : (_isListening ? Icons.stop : Icons.mic),
                        color: Colors.white, size: 40,
                      ),
                    ),
                  ),
              ],
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildUserSelector() {
    if (_sampleUsers.isEmpty) return const SizedBox.shrink();
    return SizedBox(
      height: 96,
      child: ListView.separated(
        padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
        scrollDirection: Axis.horizontal,
        itemCount: _sampleUsers.length,
        separatorBuilder: (_, __) => const SizedBox(width: 10),
        itemBuilder: (context, index) {
          final u = _sampleUsers[index];
          final isSelected = index == _selectedUserIndex;
          return GestureDetector(
            onTap: () {
              setState(() => _selectedUserIndex = index);
              _applySelectedUserChat();
            },
            child: Container(
              width: 140,
              padding: const EdgeInsets.all(8),
              decoration: BoxDecoration(
                color: isSelected ? Colors.white : Colors.white.withOpacity(0.85),
                borderRadius: BorderRadius.circular(14),
                border: Border.all(color: isSelected ? const Color(0xFF6BB8B0) : Colors.black12, width: isSelected ? 2 : 1),
              ),
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                mainAxisSize: MainAxisSize.min,
                children: [
                  Text(
                    "${u['nickname']}",
                    style: const TextStyle(fontWeight: FontWeight.bold),
                    maxLines: 1,
                    overflow: TextOverflow.ellipsis,
                  ),
                  const SizedBox(height: 4),
                  Text(
                    "Grade ${u['grade']}",
                    style: const TextStyle(fontSize: 12),
                    maxLines: 1,
                    overflow: TextOverflow.ellipsis,
                  ),
                  const SizedBox(height: 4),
                  Text(
                    "${u['recent']}",
                    style: const TextStyle(fontSize: 10, color: Colors.black54),
                    maxLines: 1,
                    overflow: TextOverflow.ellipsis,
                  ),
                ],
              ),
            ),
          );
        },
      ),
    );
  }

  void _applySelectedUserChat() {
    if (_sampleUsers.isEmpty) return;
    final chat = List<Map<String, String>>.from(_sampleUsers[_selectedUserIndex]['chat'] as List);
    setState(() {
      _chatHistory = chat;
    });
    WidgetsBinding.instance.addPostFrameCallback((_) => _scrollToBottom());
  }

  List<Map<String, dynamic>> _buildSampleUsers() {
    return [
      {
        'nickname': 'ìœ ë‚˜',
        'grade': 'C',
        'recent': 'í”¼ê³¤í•˜ì§€ë§Œ ê´œì°®ë‹¤ê³  ë§í•¨',
        'chat': [
          {'role': 'ai', 'text': 'ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë–¤ê°€ìš”? ì˜ˆ) ì¢€ ì§€ì³¤ì–´ / ê´œì°®ì€ í¸ì´ì•¼'},
          {'role': 'user', 'text': 'ì¢€ í”¼ê³¤í–ˆì–´ìš”.'},
          {'role': 'ai', 'text': 'ë§í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ì§€ê¸ˆ ëŠë‚Œì„ ì†Œì¤‘í•˜ê²Œ ë“¤ì—ˆì–´ìš”.'},
          {'role': 'ai', 'text': 'ì§€ê¸ˆ ì–´ë””ì— ìˆë‚˜ìš”? ì˜ˆ) ë°© / ê±°ì‹¤ / ì¹¨ëŒ€ ìœ„'},
          {'role': 'user', 'text': 'ê±°ì‹¤ì´ì—ìš”.'},
        ],
      },
      {
        'nickname': 'ë¯¼ì¤€',
        'grade': 'B',
        'recent': 'ì™¸ì¶œ ëŠ˜ë¦¬ê³  ì‹¶ìŒ',
        'chat': [
          {'role': 'ai', 'text': 'ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë–¤ê°€ìš”? ì˜ˆ) ì¢€ ì§€ì³¤ì–´ / ê´œì°®ì€ í¸ì´ì•¼'},
          {'role': 'user', 'text': 'ê´œì°®ì€ í¸ì´ì•¼.'},
          {'role': 'ai', 'text': 'ê´œì°®ì•„ìš”, í¸í•˜ê²Œ ë§í•´ì¤˜ì„œ ì¢‹ì•„ìš”.'},
          {'role': 'ai', 'text': 'ì§€ê¸ˆ ë¬´ì—‡ì„ í•˜ê³  ìˆë‚˜ìš”? ì˜ˆ) ëˆ„ì›Œìˆì–´ / ì•‰ì•„ì„œ ì‰¬ëŠ” ì¤‘'},
          {'role': 'user', 'text': 'ì•‰ì•„ì„œ ì‰¬ê³  ìˆì–´.'},
        ],
      },
      {
        'nickname': 'ì„œì—°',
        'grade': 'D',
        'recent': 'ë¶ˆì•ˆê³¼ íšŒí”¼ ê²½í–¥',
        'chat': [
          {'role': 'ai', 'text': 'ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë–¤ê°€ìš”? ì˜ˆ) ì¢€ ì§€ì³¤ì–´ / ê´œì°®ì€ í¸ì´ì•¼'},
          {'role': 'user', 'text': 'ê·¸ëƒ¥ ì§€ì³.'},
          {'role': 'ai', 'text': 'ì§€ê¸ˆ ìƒíƒœë¥¼ ì•Œë ¤ì¤˜ì„œ ì •ë§ ë„ì›€ì´ ëì–´ìš”.'},
          {'role': 'ai', 'text': 'ì§€ê¸ˆ ì–´ë””ì— ìˆë‚˜ìš”? ì˜ˆ) ë°© / ê±°ì‹¤ / ì¹¨ëŒ€ ìœ„'},
          {'role': 'user', 'text': 'ë°©ì´ì•¼.'},
        ],
      },
    ];
  }

  (String, String) _splitQuestionText(String text) {
    final idx = text.indexOf("ì˜ˆ)");
    if (idx == -1) return (text, "");
    final main = text.substring(0, idx).trim();
    final example = text.substring(idx).trim();
    return (main, example);
  }
}
